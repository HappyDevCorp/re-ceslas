# Load LLMs here using Langchain

# Return the LLMs as required for inference
